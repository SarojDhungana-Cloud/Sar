#!/usr/bin/env python3
"""
Interactive dashboard with:
- DATE(AD) / Nepali_Date(BS) toggle
- Block range controls
- Plotly chart + DataTable
- Python-side precomputed forecasts for the next ~3 months (DAM, RTM, IEX)
- Default view = last 14 days, plotting Avg DAM, Avg RTM, and IEX

Dependencies:
  pip install pandas requests

Run:
  python build_summary_dashboard.py
"""

from __future__ import annotations

import io
import json
import re
import sys
from typing import List, Optional, Dict, Any

import pandas as pd
import requests

# --------------------------- CONFIG ---------------------------

SUPABASE_CSV_URL = (
    "https://imloololrtufqywapowk.supabase.co/storage/v1/object/public/"
    "flat-data/summary/latest/summary.csv"
)

OUTPUT_HTML = "summary_dashboard.html"

# Prefer a full 24h window if present; otherwise fall back to first..last block in CSV
PREFERRED_FIRST_BLOCK = "00:00-00:15"
PREFERRED_LAST_BLOCK  = "23:45-24:00"

# Forecast hyperparams (Python + client will read these)
FORECAST_K_SAME_WEEKDAY = 6   # last K occurrences of same weekday
FORECAST_MIN_REQUIRED   = 3   # fallback if fewer than this
FORECAST_HORIZON_DAYS   = 90  # ~3 months forward
# --------------------------------------------------------------


def fail(msg: str):
    print(f"ERROR: {msg}", file=sys.stderr)
    sys.exit(1)


def canon(s: str) -> str:
    if s is None:
        return ""
    return re.sub(r"[\s_\-.]+", "", str(s).strip().lower())


def load_csv(url: str) -> pd.DataFrame:
    try:
        r = requests.get(url, timeout=60)
        r.raise_for_status()
    except Exception as e:
        fail(f"Could not download CSV from Supabase: {e}")
    df = pd.read_csv(
        io.BytesIO(r.content),
        dtype_backend="pyarrow" if pd.__version__ >= "2.0.0" else None,
        keep_default_na=False,
    )
    df.columns = [str(c).replace("\n", " ").strip() for c in df.columns]
    return df


def detect_date_col(df: pd.DataFrame) -> Optional[str]:
    for wanted in ("date", "dt"):
        for c in df.columns:
            if canon(c) == wanted:
                return c
    best, score = None, -1.0
    for c in df.columns:
        hit = pd.to_datetime(df[c].astype(str), errors="coerce").notna().mean()
        if hit > score:
            best, score = c, hit
    return best if score >= 0.5 else None


def detect_day_col(df: pd.DataFrame) -> Optional[str]:
    for wanted in ("dayname", "day_name", "day"):
        for c in df.columns:
            if canon(c) == wanted:
                return c
    weekdays = {"monday","tuesday","wednesday","thursday","friday","saturday","sunday"}
    best, score = None, -1.0
    for c in df.columns:
        s = df[c].astype(str).str.strip().str.lower()
        hit = s.isin(weekdays).mean()
        if hit > score:
            best, score = c, hit
    return best if score >= 0.5 else None


def detect_type_col(df: pd.DataFrame) -> Optional[str]:
    for wanted in ("datetype","date type","type"):
        for c in df.columns:
            if canon(c) == canon(wanted):
                return c
    pat = re.compile(r"(?:^|[^A-Z])(?:DAM|RTM)(?:[^A-Z]|$)", re.I)
    best, score = None, -1.0
    for c in df.columns:
        hit = df[c].astype(str).str.contains(pat).mean()
        if hit > score:
            best, score = c, hit
    return best if score >= 0.2 else None


def looks_like_block(colname: str) -> bool:
    s = str(colname).strip()
    return bool(re.match(r"^\d{1,2}:\d{2}\s*-\s*\d{1,2}:\d{2}$", s))


def has_type_str(tp: str, needle: str) -> bool:
    if not tp:
        return False
    return re.search(rf"(?:^|[^A-Z]){re.escape(needle)}(?:[^A-Z]|$)", str(tp).upper()) is not None


def recency_weighted_series(
    df_rows: List[Dict[str, Any]],
    span: List[str],
    date_field: str,
    day_field: str,
    type_field: str,
    target_date: str,
    target_type: str,
    k: int,
    min_req: int,
) -> Dict[str, Any]:
    """Python-side forecast for one market (DAM/RTM or ALL).
    Returns dict: {'y': [..], 'used_dates': [...], 'weekday': 'Monday', 'fallback': bool}
    """
    weekday = pd.to_datetime(target_date, errors="coerce").day_name() if target_date else ""
    # Unique dates of same weekday & type
    same_wd_dates = []
    seen = set()
    for r in df_rows:
        d = r.get(date_field, "")
        if not d:
            continue
        if r.get(day_field, "").strip().lower() != (weekday or "").lower():
            continue
        tp = r.get(type_field, "")
        if target_type != "ALL" and not has_type_str(tp, target_type):
            continue
        if d not in seen:
            same_wd_dates.append(d)
            seen.add(d)
    same_wd_dates = sorted(same_wd_dates)
    used_dates = same_wd_dates[-k:]

    # compute weighted mean across rows with dates in used_dates
    if len(used_dates) >= min_req:
        weights = {d: (i + 1) for i, d in enumerate(used_dates)}  # ascending recency 1..K
        y = []
        for c in span:
            sw = 0.0
            wsum = 0.0
            for r in df_rows:
                d = r.get(date_field, "")
                if d not in weights:
                    continue
                tp = r.get(type_field, "")
                if target_type != "ALL" and not has_type_str(tp, target_type):
                    continue
                raw = r.get(c, "")
                try:
                    v = float(str(raw).replace(",", "")) if str(raw).strip() != "" else None
                except Exception:
                    v = None
                if v is None:
                    continue
                w = weights[d]
                sw += v * w
                wsum += w
            y.append(sw / wsum if wsum else None)
        return {"y": y, "used_dates": used_dates, "weekday": weekday, "fallback": False}
    else:
        # fallback: overall average for that type across all rows
        y = []
        for c in span:
            s = 0.0
            n = 0
            for r in df_rows:
                tp = r.get(type_field, "")
                if target_type != "ALL" and not has_type_str(tp, target_type):
                    continue
                raw = r.get(c, "")
                try:
                    v = float(str(raw).replace(",", "")) if str(raw).strip() != "" else None
                except Exception:
                    v = None
                if v is None:
                    continue
                s += v
                n += 1
            y.append(s / n if n else None)
        return {"y": y, "used_dates": used_dates, "weekday": weekday, "fallback": True}


def make_forecast_rows_for_date(
    df_rows: List[Dict[str, Any]],
    blocks: List[str],
    date_field: str,
    day_field: str,
    type_field: str,
    target_date: str,
    nep_col: Optional[str],
    k: int,
    min_req: int,
) -> Dict[str, Any]:
    """Create Python-side forecast rows for DAM, RTM and IEX for a target date."""
    dam = recency_weighted_series(df_rows, blocks, date_field, day_field, type_field,
                                  target_date, "DAM", k, min_req)
    rtm = recency_weighted_series(df_rows, blocks, date_field, day_field, type_field,
                                  target_date, "RTM", k, min_req)

    # IEX = avg pointwise (skip nulls)
    yiex = []
    for i in range(len(blocks)):
        vals = []
        a = dam["y"][i]
        b = rtm["y"][i]
        if a is not None:
            vals.append(a)
        if b is not None:
            vals.append(b)
        yiex.append(sum(vals) / len(vals) if vals else None)

    wd = dam["weekday"] or rtm["weekday"] or (pd.to_datetime(target_date, errors="coerce").day_name() if target_date else "")

    def mk_row(label: str, arr: List[Optional[float]]) -> Dict[str, Any]:
        r = {date_field: target_date, day_field: wd, type_field: label}
        if nep_col:
            r[nep_col] = ""
        for c, v in zip(blocks, arr):
            r[c] = v if v is not None else ""
        return r

    rows = [
        mk_row("Forecast DAM", dam["y"]),
        mk_row("Forecast RTM", rtm["y"]),
        mk_row("Forecast IEX", yiex),
    ]
    meta = {
        "k": k,
        "min_required": min_req,
        "used_dates_dam": dam["used_dates"],
        "used_dates_rtm": rtm["used_dates"],
        "weekday": wd,
        "fallback_dam": dam["fallback"],
        "fallback_rtm": rtm["fallback"],
    }
    return {"rows": rows, "yDam": dam["y"], "yRtm": rtm["y"], "yIex": yiex, "meta": meta}


def main():
    # 1) Load CSV
    df = load_csv(SUPABASE_CSV_URL)
    if df.empty:
        fail("CSV appears empty.")

    # 2) Detect core columns
    date_col = detect_date_col(df)
    day_col  = detect_day_col(df)
    type_col = detect_type_col(df)
    if not all([date_col, day_col, type_col]):
        fail(f"Could not detect core columns. Columns = {list(df.columns)}")

    # Parse DATE to datetime for safe min/max
    date_parsed = pd.to_datetime(df[date_col], errors="coerce")
    date_valid = date_parsed.dropna()
    dmin_iso = date_valid.min().strftime("%Y-%m-%d") if not date_valid.empty else ""
    dmax_iso = date_valid.max().strftime("%Y-%m-%d") if not date_valid.empty else ""

    # Normalize helper columns (kept in JSON as originals)
    df["_DATE"] = date_parsed.dt.strftime("%Y-%m-%d")
    df["_DAY"]  = df[day_col].astype(str).str.strip()
    df["_TYPE"] = df[type_col].astype(str).str.strip()

    # 3) Block columns
    block_cols: List[str] = [c for c in df.columns if looks_like_block(c)]
    if not block_cols:
        fail("No block columns found (e.g., '00:00-00:15').")

    # 4) Optional Nepali (BS) date column
    nepali_col = None
    for cand in ("nepali_date", "nepalidate", "nepali date"):
        for c in df.columns:
            if canon(c) == cand:
                nepali_col = c
                break
        if nepali_col:
            break
    has_nepali = bool(nepali_col)

    # Prepare rows dicts that include only what we will export
    keep_cols = ["_DATE", "_DAY", "_TYPE"] + ([nepali_col] if has_nepali else []) + block_cols
    df_for_json = df[keep_cols].fillna("")
    data_records = df_for_json.to_dict(orient="records")

    # ---- Python-side precomputation: forecasts for next ~3 months ----
    forecast_map: Dict[str, Any] = {}
    forecast_dates: List[str] = []
    if dmax_iso:
        start = pd.to_datetime(dmax_iso) + pd.Timedelta(days=1)
        for i in range(FORECAST_HORIZON_DAYS):
            tgt = (start + pd.Timedelta(days=i)).strftime("%Y-%m-%d")
            fc = make_forecast_rows_for_date(
                data_records,
                block_cols,
                "_DATE",
                "_DAY",
                "_TYPE",
                tgt,
                nepali_col,
                FORECAST_K_SAME_WEEKDAY,
                FORECAST_MIN_REQUIRED,
            )
            forecast_map[tgt] = fc
            forecast_dates.append(tgt)

    # dropdown values
    types_present = set()
    for r in data_records:
        tp = (r["_TYPE"] or "").upper()
        if "DAM" in tp:
            types_present.add("DAM")
        if "RTM" in tp:
            types_present.add("RTM")
    type_options = ["ALL"] + [t for t in ["DAM", "RTM"] if t in types_present]
    days = sorted({(r["_DAY"] or "") for r in data_records if (r["_DAY"] or "")})
    day_options  = ["All"] + days

    # 24h & default AD last-14-days window
    first_block = PREFERRED_FIRST_BLOCK if PREFERRED_FIRST_BLOCK in block_cols else block_cols[0]
    last_block  = PREFERRED_LAST_BLOCK  if PREFERRED_LAST_BLOCK  in block_cols else block_cols[-1]

    if dmax_iso:
        default_second = dmax_iso
        default_first  = (pd.to_datetime(dmax_iso) - pd.Timedelta(days=13)).strftime("%Y-%m-%d")
    else:
        default_first = default_second = ""

    payload = {
        "rows": data_records,
        "block_cols": block_cols,
        "has_nepali": has_nepali,
        "nep_col": nepali_col if has_nepali else "",
        "day_options": day_options,
        "type_options": type_options,
        "default_first_ad": default_first,   # last 14 days by default
        "default_second_ad": default_second,
        "csv_url": SUPABASE_CSV_URL,
        "default_block1": first_block,
        "default_blockn": last_block,
        "col_names": {"DATE_AD": "_DATE", "DAY": "_DAY", "TYPE": "_TYPE", "NEPALI": nepali_col if has_nepali else ""},
        "forecast": {"k": FORECAST_K_SAME_WEEKDAY, "min_required": FORECAST_MIN_REQUIRED, "last_date_ad": dmax_iso},
        "forecast_map": forecast_map,          # Python-generated forecasts keyed by date
        "forecast_dates": forecast_dates,      # list of available forecast dates
    }

    # --------------------------- HTML TEMPLATE ---------------------------
    HTML_TEMPLATE = r"""<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Summary – Custom Dashboard</title>

<script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
<link rel="stylesheet" href="https://cdn.datatables.net/2.0.5/css/dataTables.dataTables.min.css"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdn.datatables.net/2.0.5/js/dataTables.min.js"></script>

<style>
  body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, Noto Sans; margin: 20px; }
  .grid { display: grid; grid-template-columns: repeat(6, minmax(160px, 1fr)); gap: 12px; }
  .card { background: #fff; border: 1px solid #eaecef; border-radius: 12px; padding: 16px; margin-bottom: 18px; box-shadow: 0 2px 8px rgba(0,0,0,0.04); }
  label { font-size: 12px; color: #555; display:block; margin-bottom:6px; }
  input[type="date"], select { width: 100%; padding: 8px 10px; border:1px solid #dfe3e8; border-radius:8px; }
  button.primary { padding: 10px 14px; border: 0; border-radius: 10px; background: #2563eb; color: white; font-weight: 600; cursor: pointer; }
  button.primary:hover { background: #1d4ed8; }
  #chart { height: 420px; }
  .note { font-size: 12px; color:#666; white-space:pre-wrap; }
  .row { display:flex; align-items:center; gap:16px; flex-wrap:wrap; }
  .inline { display:flex; align-items:center; gap:8px; }
</style>
</head>
<body>

<div class="card">
  <h1 style="margin:0 0 12px 0;">Summary – Custom Dashboard</h1>
  <div class="note">Data source: <code id="csvUrl">__CSV__</code></div>
</div>

<div class="card">
  <h2 style="margin:0 8px 12px 0;">Filters</h2>
  <div class="row" style="margin-bottom:10px;">
    <div class="inline">
      <input type="radio" id="modeAD" name="dateMode" value="AD" checked>
      <label for="modeAD"><b>Use DATE (AD)</b></label>
    </div>
    <div class="inline">
      <input type="radio" id="modeBS" name="dateMode" value="BS" disabled>
      <label for="modeBS"><b>Use Nepali_Date (BS)</b></label>
    </div>
    <span class="note" id="nepAvail"></span>
  </div>

  <div class="grid" id="adControls">
    <div>
      <label>First_Date (AD)</label>
      <input type="date" id="firstDateAD" />
    </div>
    <div>
      <label>Second_Date (AD)</label>
      <input type="date" id="secondDateAD" />
    </div>
  </div>

  <div class="grid" id="bsControls" style="display:none;">
    <div>
      <label>First_Nepali_Date (BS)</label>
      <select id="firstDateBS"></select>
    </div>
    <div>
      <label>Second_Nepali_Date (BS)</label>
      <select id="secondDateBS"></select>
    </div>
  </div>

  <div class="grid" style="margin-top:10px;">
    <div>
      <label>Day_Name</label>
      <select id="dayName"></select>
    </div>
    <div>
      <label>Type</label>
      <select id="typeSel"></select>
    </div>
    <div>
      <label>Block1</label>
      <select id="blockStart"></select>
    </div>
    <div>
      <label>Blockn</label>
      <select id="blockEnd"></select>
    </div>
  </div>

  <div style="margin-top:14px;">
    <button id="generateBtn" class="primary">Generate</button>
    <span class="note" id="rowCount" style="margin-left:12px;"></span>
  </div>
</div>

<div class="card">
  <h2 style="margin:0 0 12px 0;">Chart</h2>
  <div id="chart"></div>
  <div id="forecastNotes" class="note" style="margin-top:10px;"></div>
</div>

<div class="card">
  <h2 style="margin:0 0 12px 0;">Data</h2>
  <div id="tableWrap"></div>
</div>

<script id="data-json" type="application/json">__PAYLOAD__</script>

<script>
(function() {
  const payload = JSON.parse(document.getElementById('data-json').textContent);

  const rows = payload.rows;
  const blocks = payload.block_cols.slice();
  const hasNepali = payload.has_nepali;
  const NEP_COL = payload.nep_col || "";

  const DATE = payload.col_names["DATE_AD"];
  const DAY  = payload.col_names["DAY"];
  const TYPE = payload.col_names["TYPE"];

  // Python-precomputed forecast map
  const fcMap = payload.forecast_map || {}; // date -> {rows, yDam, yRtm, yIex, meta}
  const fcDates = new Set(payload.forecast_dates || []);

  // Controls
  const modeAD  = document.getElementById('modeAD');
  const modeBS  = document.getElementById('modeBS');
  const adWrap  = document.getElementById('adControls');
  const bsWrap  = document.getElementById('bsControls');
  const fAD     = document.getElementById('firstDateAD');
  const sAD     = document.getElementById('secondDateAD');
  const fBS     = document.getElementById('firstDateBS');
  const sBS     = document.getElementById('secondDateBS');
  const daySel  = document.getElementById('dayName');
  const typeSel = document.getElementById('typeSel');
  const b1Sel   = document.getElementById('blockStart');
  const bnSel   = document.getElementById('blockEnd');
  const notesEl = document.getElementById('forecastNotes');

  // Enable BS if available
  if (hasNepali && NEP_COL) { modeBS.disabled = false; }

  // Populate defaults (AD last 14 days)
  fAD.value = payload.default_first_ad || "";
  sAD.value = payload.default_second_ad || "";

  // Populate dropdowns
  (payload.day_options || ["All"]).forEach(v => {
    const o = document.createElement('option'); o.value=v; o.textContent=v; daySel.appendChild(o);
  });
  (payload.type_options || ["ALL","DAM","RTM"]).forEach(v => {
    const o = document.createElement('option'); o.value=v; o.textContent=v; typeSel.appendChild(o);
  });
  blocks.forEach(v => {
    const o1=document.createElement('option'); o1.value=v; o1.textContent=v; b1Sel.appendChild(o1);
    const o2=document.createElement('option'); o2.value=v; o2.textContent=v; bnSel.appendChild(o2);
  });
  daySel.value = "All"; typeSel.value = "ALL";
  b1Sel.value = payload.default_block1 || blocks[0];
  bnSel.value = payload.default_blockn || blocks[blocks.length-1];

  function refreshMode(){
    if (modeAD.checked){ adWrap.style.display=""; bsWrap.style.display="none";}
    else { adWrap.style.display="none"; bsWrap.style.display="";}
  }
  modeAD.addEventListener('change', refreshMode);
  modeBS.addEventListener('change', refreshMode);
  refreshMode();

  // Utils
  function num(v){ const n=Number(String(v).replace(/[, ]/g,'')); return Number.isFinite(n)?n:null; }
  function rowStats(r, span){
    let mn=null,mx=null,s=0,n=0;
    span.forEach(c=>{ const v=num(r[c]); if(v===null) return; mn=mn===null?v:Math.min(mn,v); mx=mx===null?v:Math.max(mx,v); s+=v;n++; });
    return {min:mn===null?"":mn, max:mx===null?"":mx, avg:n? s/n:""};
  }
  function addAggregateRows(rowsWithStats, span){
    const aggMin={}, aggMax={}, aggAvg={};
    span.forEach(c=>{
      let mn=null,mx=null,s=0,n=0;
      rowsWithStats.forEach(r=>{ const v=num(r[c]); if(v===null) return; mn=mn===null?v:Math.min(mn,v); mx=mx===null?v:Math.max(mx,v); s+=v;n++; });
      aggMin[c]=mn===null?"":mn; aggMax[c]=mx===null?"":mx; aggAvg[c]=n? s/n:"";
    });
    let minOfMin=null,maxOfMax=null,sAvg=0,nAvg=0;
    rowsWithStats.forEach(r=>{ const a=num(r.__MIN), b=num(r.__MAX), c=num(r.__AVG);
      if(a!==null) minOfMin=minOfMin===null?a:Math.min(minOfMin,a);
      if(b!==null) maxOfMax=maxOfMax===null?b:Math.max(maxOfMax,b);
      if(c!==null){ sAvg+=c; nAvg++; }});
    return [
      Object.assign({}, aggMin, {_LABEL:"Aggregate-Min", __MIN:minOfMin===null?"":minOfMin, __MAX:"", __AVG:""}),
      Object.assign({}, aggMax, {_LABEL:"Aggregate-Max", __MIN:"", __MAX:maxOfMax===null?"":maxOfMax, __AVG:""}),
      Object.assign({}, aggAvg, {_LABEL:"Aggregate-Avg", __MIN:"", __MAX:"", __AVG:nAvg? sAvg/nAvg:""})
    ];
  }
  function hasType(tp, needle){ return new RegExp("(?:^|[^A-Z])"+needle+"(?:[^A-Z]|$)","i").test(String(tp||"")); }

  function selectedBlockSpan(){
    const start=b1Sel.value, end=bnSel.value;
    const i1=blocks.indexOf(start), i2=blocks.indexOf(end);
    if(i1<0||i2<0) return [];
    const a=Math.min(i1,i2), b=Math.max(i1,i2);
    return blocks.slice(a,b+1);
  }

  function filterRows(){
    const useBS = !modeAD.checked && hasNepali && NEP_COL;
    let lo="",hi="",dateField="";
    if(useBS){ lo=fBS.value||""; hi=sBS.value||""; dateField=NEP_COL; }
    else{ lo=fAD.value||""; hi=sAD.value||""; dateField=DATE; }
    const day=(daySel.value||"All").toLowerCase();
    const typ=(typeSel.value||"ALL").toUpperCase();
    return rows.filter(r=>{
      const d=(r[dateField]||"").trim();
      const dn=(r[DAY]||"").trim().toLowerCase();
      if(!(d && (!lo||d>=lo) && (!hi||d<=hi))) return false;
      if(day!=="all" && dn!==day) return false;
      if(typ==="ALL") return true;
      return hasType(r[TYPE], typ);
    });
  }

  function seriesAvgByType(filtered, span, typeNeedle) {
    return span.map(c => {
      let s=0, n=0;
      filtered.forEach(r => {
        if (!hasType(r[TYPE], typeNeedle)) return;
        const v = num(r[c]); if (v===null) return;
        s+=v; n+=1;
      });
      return n ? s/n : null;
    });
  }

  // Chart + Table
  let dt=null;

  function render(){
    const span = selectedBlockSpan();
    const useForecast = (fAD.value && sAD.value && fAD.value===sAD.value && fcDates.has(fAD.value));
    const traces=[];
    const notes=[];

    let tableRows=[];

    if(useForecast){
      const fc = fcMap[fAD.value];
      // traces
      traces.push({x:span, y:span.map((_,i)=>fc.yDam[i]), mode:'lines+markers', name:'Forecast (DAM)', line:{dash:'dash'}});
      traces.push({x:span, y:span.map((_,i)=>fc.yRtm[i]), mode:'lines+markers', name:'Forecast (RTM)', line:{dash:'dash'}});
      traces.push({x:span, y:span.map((_,i)=>fc.yIex[i]), mode:'lines+markers', name:'Forecast (IEX)', line:{dash:'dashdot'}});
      // table rows from python pre-gen
      tableRows = fc.rows.map(r=>{
        const rr=Object.assign({}, r, {_LABEL:r[DATE]});
        const st=rowStats(rr, span); rr.__MIN=st.min; rr.__MAX=st.max; rr.__AVG=st.avg; return rr;
      });
      notes.push(`Python precomputed forecast for ${fAD.value}
K=${fc.meta.k}, MinRequired=${fc.meta.min_required}
Used dates DAM: ${(fc.meta.used_dates_dam||[]).join(", ") || "—"}
Used dates RTM: ${(fc.meta.used_dates_rtm||[]).join(", ") || "—"}
Last data date: ${payload.forecast.last_date_ad || "—"}`);
      document.getElementById('rowCount').textContent = `Rows: ${tableRows.length} (forecast)`;

      Plotly.react(document.getElementById('chart'), traces, {
        title:`Forecast for ${fAD.value} — ALL`, xaxis:{title:'Block'}, yaxis:{title:'Value'},
        template:'plotly_white', legend:{title:'Series'}, margin:{l:40,r:20,t:60,b:40}, hovermode:'x unified'
      }, {responsive:true, displayModeBar:false});
    } else {
      // normal mode
      const filtered = filterRows();
      // Default requirement: for ALL + All day_name, plot Avg DAM, Avg RTM, and IEX
      const typ=(typeSel.value||"ALL").toUpperCase();
      const day=(daySel.value||"All").toLowerCase();
      if(typ==="ALL" && day==="all"){
        const yDam = seriesAvgByType(filtered, span, "DAM");
        const yRtm = seriesAvgByType(filtered, span, "RTM");
        const yIex = span.map((_,i)=>{
          const A=yDam[i], B=yRtm[i];
          const vals=[]; if(Number.isFinite(A)) vals.push(A); if(Number.isFinite(B)) vals.push(B);
          return vals.length? (vals.reduce((x,y)=>x+y,0)/vals.length): null;
        });
        traces.push({x:span, y:yDam, mode:'lines+markers', name:'Avg DAM'});
        traces.push({x:span, y:yRtm, mode:'lines+markers', name:'Avg RTM'});
        traces.push({x:span, y:yIex, mode:'lines+markers', name:'IEX (Avg of DAM & RTM)'});
      } else {
        // existing average across filtered rows (single series)
        const means = span.map(c=>{
          let s=0,n=0; filtered.forEach(r=>{ const v=num(r[c]); if(v===null) return; s+=v;n++; });
          return n? s/n:null;
        });
        traces.push({x:span, y:means, mode:'lines+markers', name:'Avg (filtered)'});
      }

      // table
      tableRows = filterRows().map(r=>{
        const rr=Object.assign({}, r, {_LABEL:r[DATE]});
        const st=rowStats(rr, span); rr.__MIN=st.min; rr.__MAX=st.max; rr.__AVG=st.avg; return rr;
      });
      document.getElementById('rowCount').textContent = `Rows: ${tableRows.length}`;

      Plotly.react(document.getElementById('chart'), traces, {
        title:"Block-wise view", xaxis:{title:'Block'}, yaxis:{title:'Value'},
        template:'plotly_white', legend:{title:'Series'}, margin:{l:40,r:20,t:60,b:40}, hovermode:'x unified'
      }, {responsive:true, displayModeBar:false});
    }

    notesEl.textContent = notes.join("\n");

    // DataTable
    const cols = [];
    cols.push({title:'DATE', data:'_LABEL'});
    if (hasNepali && NEP_COL) cols.push({title:'Nepali_Date', data:NEP_COL});
    cols.push({title:'Day Name', data:DAY});
    cols.push({title:'Date_Type', data:TYPE});
    selectedBlockSpan().forEach(c=>cols.push({title:c, data:c}));
    cols.push({title:'Min', data:'__MIN'});
    cols.push({title:'Max', data:'__MAX'});
    cols.push({title:'Avg', data:'__AVG'});

    const aggs = addAggregateRows(tableRows, selectedBlockSpan());
    const tableData = tableRows.concat(aggs);

    const wrap = document.getElementById('tableWrap');
    wrap.innerHTML = '<table id="dataTable" class="display compact nowrap" style="width:100%"></table>';
    if (dt) { try{dt.destroy();}catch(e){} dt=null; }
    dt = new $.fn.dataTable.Api($('#dataTable').DataTable({
      data: tableData, columns: cols, paging:true, searching:true, ordering:true,
      scrollY:'420px', scrollX:true, deferRender:true, scroller:true,
      columnDefs:[{targets:'_all', render:function(data,type){
        if(data===""||data==null) return "";
        if(type==='display' && !isNaN(Number(data))) { const n=Number(data); return Number.isFinite(n)? n.toLocaleString():data; }
        return data;
      }}],
      createdRow:function(row,data){
        const label=data._LABEL||'';
        if(label==='Aggregate-Min'||label==='Aggregate-Max'||label==='Aggregate-Avg'){
          $(row).css({'font-weight':'600','border-top':'2px solid #999'});
        }
      }
    }));
  }

  // Initial render (defaults to last 14 days Avg DAM/RTM/IEX)
  render();

  // Interactions
  document.getElementById('generateBtn').addEventListener('click', render);
  modeAD.addEventListener('change', render);
  modeBS.addEventListener('change', render);
  daySel.addEventListener('change', render);
  typeSel.addEventListener('change', render);
  b1Sel.addEventListener('change', render);
  bnSel.addEventListener('change', render);
})();
</script>

</body>
</html>
"""

    # Fill placeholders safely
    html = (
        HTML_TEMPLATE
        .replace("__CSV__", SUPABASE_CSV_URL)
        .replace("__PAYLOAD__", json.dumps(payload))
    )

    with open(OUTPUT_HTML, "w", encoding="utf-8") as f:
        f.write(html)

    print(f"Dashboard written to: {OUTPUT_HTML}")


if __name__ == "__main__":
    main()
